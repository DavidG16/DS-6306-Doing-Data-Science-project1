# 2-D plots example only
# Sepal.Length vs Sepal.Width
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 5) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery")
# plot source:
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df
# Use ggplot
# 2-D plots example only
# Sepal.Length vs Sepal.Width
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery")
# plot source:
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df
# Use ggplot
# 2-D plots example only
# Sepal.Length vs Sepal.Width
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
# plot source:
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = ipa_ale)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = ipa_ale, fill = predicted)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +
geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) #+
#  geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +   geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Boundery") + theme_economist()
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
plot.df
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +   geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Prediction Boundery") + theme_economist()
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tidyr)
library(plyr)
library(dplyr)
library(tidyverse)
library(caret)
library(class)
library(e1071)
library(data.table)
library(gganimate)
library(GGally)
require(ggthemes)
# Load the CSVs
breweries = read.csv(".Data/Breweries.csv")
# Load the CSVs
breweries = read.csv(".Data/Breweries.csv")
# Load the CSVs
breweries = read.csv("./Data/Breweries.csv")
# Load the CSVs
breweries = read.csv("./Data/Breweries.csv")
# Load the CSVs
breweries = read.csv("./Data/Breweries.csv")
# Load the CSVs
breweries = read.csv("./Data/Breweries.csv")
beers = read.csv("./Data/Beers.csv")
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tidyr)
library(plyr)
library(dplyr)
library(tidyverse)
library(caret)
library(class)
library(e1071)
library(data.table)
library(gganimate)
library(GGally)
require(ggthemes)
# Load the CSVs
breweries = read.csv("./Data/Breweries.csv")
beers = read.csv("./Data/Beers.csv")
# Question 1
# Filter and plot the number of breweries in each state.
breweries_per_state = breweries %>% count(State)
breweries_per_state %>% ggplot() + geom_bar(aes(State, n), fill="steelblue" ,stat = 'identity')+ geom_text(stat = "count", aes(State, label = n, vjust=-0.1),size = 2.5, color = "darkred")+ labs(x='', y="Number of Breweries", title='Number of Breweries per State') +theme_economist()+ theme(axis.text.x = element_text(angle = 60, hjust = 1,size = 6))
# Building Heatmap of US for number of breweries in each state
breweries_per_state_1 = breweries_per_state
# Remove any whitespaces present in the dataset
breweries_per_state_1$State = trimws(breweries_per_state_1$State,which=c("both"),whitespace = "[ ]")
# Setup dataframe for State name lookup
lookup = data.frame(abbr = state.abb, State = state.name)
# Merge the dataset
breweries_per_state_1 = merge(breweries_per_state_1, lookup, by.x="State", by.y="abbr")
# Change the state names to lowercase
breweries_per_state_1$StateLower = tolower(breweries_per_state_1$State.y)
states = map_data("state")
map.df = merge(states,breweries_per_state_1, by.x = "region", by.y ="StateLower",  all.x=T)
map.df = map.df[order(map.df$order),]
# Rename the column Name
colnames(map.df)[8] = "Num.of.Breweries"
# Plot the breweries data on US political map
ggplot(map.df, aes(x=long,y=lat,group=group))+
geom_polygon(aes(fill=Num.of.Breweries))+
geom_path()+
scale_fill_gradientn(colours=rev(heat.colors(5)), na.value="grey90") + ggtitle("Breweries by State")+theme_map()
# Question 2 - Merge beer data with the breweries data
data = merge(x=breweries, y=beers, by.y ="Brewery_id" , by.x = "Brew_ID")
# Rename the variables
data = data%>%rename(Beer.Name=Name.y, Brewery = Name.x)
nrow(data)
head(data,6)
tail(data,6)
# Questions 3 - Handle missing values
missing.values <- data %>%
gather(key = "key", value = "val") %>%
mutate(is.missing = is.na(val)) %>%
group_by(key, is.missing) %>%
summarise(num.missing = n()) %>%
filter(is.missing==T) %>%
select(-is.missing) %>%
arrange(desc(num.missing))
# Plot the missing values to identify the variables with missing data.
missing.values %>% ggplot() + geom_bar(aes(x=key, y=num.missing), fill="steelblue",stat = 'identity') + geom_text(stat = "count", aes(key, label = num.missing, vjust=-0.2),size = 4, color = "white")+
labs(x='', y="Number of missing values", title='Number of missing values') +theme_economist()+
theme(axis.text.x = element_text(angle = 0, hjust = 1))
# Questions 3 - Handle missing values
# Plot ABV distribution
data %>% ggplot() + geom_histogram(aes(x=ABV), fill="steelblue") +theme_economist()+
labs(x="ABV", y="Count", title="ABV Distribution")
# Plot IBU distribution
data %>% ggplot() + geom_histogram(aes(x=IBU), fill="steelblue") +theme_economist()+
labs(x="IBU", y="Count", title="IBU Distribution")
# Get rid of special characters in the beer styles
data$Style = gsub("[^0-9A-Za-z' ]"," " , data$Style ,ignore.case = TRUE)
#Deal with NA in IBU
# Finds the median value per beer style
meanIBU = matrix(nrow = 100)
styles = list()
for (i in 1:length(unique(data$Style)) )
{
beer_style = unique(data$Style)[i]
ibu_mean = mean(data[grep(beer_style, data$Style, ignore.case = T),]$IBU,na.rm = T )
meanIBU[i] = ibu_mean
styles[[i]] = beer_style
}
# Create a new styles dataframe with the IBU medians per beer style
styles_impute = data.frame(IBU=meanIBU, Style = matrix(unlist(styles), nrow=length(styles), byrow=T))
# merge the beer styles median IBU dataframe with the working dataframe on style name
impute_data = merge(data, styles_impute, by.x="Style", by.y="Style")
# If NA in original IBU value, then use median IBU per style, else use original value
impute_data = impute_data %>% mutate(imputed_IBU = ifelse(is.na(IBU.x) == TRUE,IBU.y,IBU.x))
# Impute any impute_data value with the median for the ABV and imputed_IBU columns
impute_data= impute_data %>% mutate_at(vars(ABV,imputed_IBU),~ifelse(is.na(.x), median(.x, na.rm = TRUE), .x))
# Get rid of the 5 rows without a beer style.
impute_data = impute_data%>% filter(!Style=="")
# Drop redundant columns
drops =  c("IBU.x","IBU.y")
impute_data = impute_data[ , !(names(impute_data) %in% drops)]
# Question 4 - Compute the median alcohol content and international bitterness unit for each state. Plot a bar chart to compare.
# Calculate Median IBU
median_ibu_state = aggregate(impute_data[, 10], list(impute_data$State), median)
# Plot median IBU by state
median_ibu_state %>% ggplot() + geom_bar(aes(Group.1, x),fill="steelblue", stat = 'identity') +
labs(x='', y="IBU Value", title='IBU by State') + theme_economist()+
theme(axis.text.x = element_text(angle = 60, hjust = 1, size=6))
# Calculate Median ABV
median_abv_state = aggregate(impute_data[, 8], list(impute_data$State), median)
# Plot Median ABV by State
median_abv_state %>% ggplot() + geom_bar(aes(Group.1, x), fill="steelblue", stat = 'identity') +
labs(x='', y="ABV Value", title='ABV by State') + theme_economist()+
theme(axis.text.x = element_text(angle = 60, hjust = 1, size = 6 ))
# Question 5 - Which state has the maximum alcoholic (ABV) beer?
impute_data %>% filter(ABV==max(ABV))
# Question 5 -Which state has the most bitter (IBU) beer?
impute_data %>% filter(imputed_IBU==max(imputed_IBU))
# Question 6 - Comment on the summary statistics and distribution of the ABV variable.
# Calculate Summary
summary(impute_data$ABV)
# Histogram for Distribution
impute_data %>% ggplot() + geom_histogram(aes(ABV), fill="steelblue") +
labs(x='ABV Value', y="count", title='ABV Distribution') + theme_economist()
# Boxplot for distribution
impute_data %>% ggplot() + geom_boxplot(aes(ABV), fill="steelblue") + theme_economist()+
labs(x='ABV Value', title='ABV Boxplot')
# Question 7 - Is there an apparent relationship between the bitterness of the beer and its alcoholic content? Draw a scatter plot.  Make your best judgment of a relationship and EXPLAIN your answer.
impute_data %>% ggplot() + geom_point(aes(x=ABV, y=imputed_IBU), color="steelblue", size = 1.5) + geom_smooth(aes(x=ABV, y=imputed_IBU),method = "lm")+ labs(x='ABV Value', y="IBU Value", title="Relation between IBU and ABV") + theme_economist() + annotate("text",x=0.12, y=135, label="Correlation: 58.00%", color="darkred", size=4)
cor(impute_data$ABV, impute_data$imputed_IBU, method = "pearson")
lm1<-lm(ABV~imputed_IBU, data = impute_data)
summary(lm1)
# Question 8 - Budweiser would also like to investigate the difference with respect to IBU and ABV between IPAs (India Pale Ales) and other types of Ale (any beer with “Ale” in its name other than IPA).  You decide to use KNN classification to investigate this relationship.  Provide statistical evidence one way or the other. You can of course assume your audience is comfortable with percentages … KNN is very easy to understand conceptually.
# Create new ipa_ale column based on regex from the beer style column
impute_data$ipa_ale = ifelse(grepl("ipa", impute_data$Style, ignore.case = T), "ipa",
ifelse(grepl("ale", impute_data$Style, ignore.case = T), "ale", "Other"))
# Filter out other type
ale_ipa = impute_data %>% filter(!ipa_ale=="Other")
#Choose the best K
set.seed(12)
splitPerc = .70
# Split the dataset into train and test
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Run iterations to find the best K
iterations = 50
accs = data.frame(accuracy = numeric(iterations), k = numeric(iterations))
for(i in 1:iterations)
{
classification = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=i)
cm = confusionMatrix(table(test$ipa_ale, classification ), positive="ale")
accs$accuracy[i] = cm$overall[1]
accs$k[i] = i
}
# Plot the K values with accuracy variation
plot(accs$k,accs$accuracy, type = "l", xlab = "Value of k", ylab = "Accuracy Percentage", main = "Best Value of K")
axis(side = 2, at = c(0:50, 5))
box()
# Run 1000 iterations  on different train/test sets. We will compute the average accuracy, specificity and Sensitivity.
iterations = 1000
masterAcc = matrix(nrow = iterations)
masterSensitivity = matrix(nrow = iterations)
masterSpecificity = matrix(nrow = iterations)
splitPerc = .7 #Training / Test split Percentage
for(j in 1:iterations)
{
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
classification = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
cm = confusionMatrix(table(test$ipa_ale, classification ), positive="ale")
masterAcc[j] = cm$overall[1]
masterSpecificity[j] = cm$byClass[2]
masterSensitivity[j] = cm$byClass[1]
}
MeanAcc = colMeans(masterAcc)
MeanSpecificity = colMeans(masterSpecificity)
MeanSensitivity = colMeans(masterSensitivity)
MeanAcc
MeanSpecificity
MeanSensitivity
splitPerc = .70
set.seed(j*49+15)
trainIndices = sample(1:dim(ale_ipa)[1],round(splitPerc * dim(ale_ipa)[1]))
train = ale_ipa[trainIndices,]
test = ale_ipa[-trainIndices,]
# Do knn
fit = knn(train[,c(8,10)], test[,c(8,10)],train$ipa_ale,k=5)
# Create a dataframe to simplify charting
plot.df = data.frame(test, predicted = fit)
plot.df$ipa_ale = as.factor(plot.df$ipa_ale)
# First use Convex hull to determine boundary points of each cluster
plot.df1 = data.frame(x = plot.df$imputed_IBU,
y = plot.df$ABV,
predicted = plot.df$predicted)
find_hull = function(df) df[chull(df$x, df$y), ]
boundary = ddply(plot.df1, .variables = "predicted", .fun = find_hull)
ggplot(plot.df, aes(imputed_IBU, ABV, color = predicted, fill = predicted)) +
geom_point(size = 2) +   geom_polygon(data = boundary, aes(x,y), alpha = 0.5) + ggtitle("KNN Clusters Prediction Boundaries") + theme_economist() + xlab("IBU")
# plot source: https://stackoverflow.com/questions/35402850/how-to-plot-knn-clusters-boundaries-in-r
# Question 9 - Knock their socks off!  Find one other useful inference from the data that you feel Budweiser may be able to find value in.  You must convince them why it is important and back up your conviction with appropriate statistical evidence.
library(wordcloud)
#install.packages("RColorBrewer")
library(RColorBrewer)
#install.packages("wordcloud2")
library(wordcloud2)
#install.packages("tm")
library(tm)
# Set Beer Style as Vector
text = as.vector(impute_data['Style'])
docs = Corpus(VectorSource(text))
# Remove punctuations, whitespaces and numbers
docs = docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
# Move to lower case
docs = tm_map(docs, content_transformer(tolower))
# Ignore Stop Words
docs = tm_map(docs, removeWords, stopwords("english"))
tdm = TermDocumentMatrix(docs)
matrix = as.matrix(tdm)
words = sort(rowSums(matrix),decreasing=TRUE)
# Make a dataframe
df_style = data.frame(word = names(words),freq=words)
# Set Beer Name as Vector
text = as.vector(impute_data$Beer.Name)
docs = Corpus(VectorSource(text))
# Remove punctuations, whitespaces and numbers
docs = docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs = tm_map(docs, content_transformer(tolower))
# Ignore Stop Words
docs = tm_map(docs, removeWords, stopwords("english"))
tdm = TermDocumentMatrix(docs)
matrix = as.matrix(tdm)
words = sort(rowSums(matrix),decreasing=TRUE)
# Make a dataframe
df_name = data.frame(word = names(words),freq=words)
# Create the Word cloud of Beer Style
wordcloud(words = df_style$word, freq = df_style$freq, min.freq = 1,max.words=100, random.order=FALSE, rot.per=0.35,colors=brewer.pal(8, "Dark2"))
# Create the Word cloud of Beer Style
set.seed(1234) # for reproducibility
wordcloud(words = df_name$word, freq = df_name$freq, min.freq = 1,max.words=100, random.order=FALSE, rot.per=0.35,colors=brewer.pal(6, "Dark2"))
ale_ipa$ipa_ale = as.factor(ale_ipa$ipa_ale)
t.test(ale_ipa$imputed_IBU ~ale_ipa$ipa_ale)
t.test(ale_ipa$ABV ~ale_ipa$ipa_ale)
# Seperate ALE
ale = impute_data %>% filter(ipa_ale=="ale")
# Seperate IPA
ipa = impute_data %>% filter(ipa_ale=="ipa")
# Step 1 -  group by state and count the number of beer in each state IPA and ALE
ipa_state =ipa %>% count(State)
ale_state =ale %>% count(State)
ale_state  = ale_state %>% rename(ALE = n)
ipa_state  = ipa_state %>% rename(IPA = n)
# Merge the Data Frame
beers_state = merge(ale_state, ipa_state, by="State")
# Step 2-  Filter for the top 5 states for Beer Consumption
beers_state_top_5= beers_state %>% filter(State == " CA" | State== " TX" | State== " FL" | State== " NY" | State== " PA")
# Step 3-  Plot # of beers that are ale or ipa per state
beers_state_tall = beers_state_top_5 %>% gather(key= Beers, value=Value, ALE:IPA)
beers_state_tall %>% ggplot(aes(State, Value, fill=Beers), ) + geom_col(position="dodge") + theme_economist() + ggtitle("Beer Type for The Top 5 States (Consumption)")
# Question 7 - Is there an apparent relationship between the bitterness of the beer and its alcoholic content? Draw a scatter plot.  Make your best judgment of a relationship and EXPLAIN your answer.
impute_data %>% ggplot() + geom_point(aes(x=ABV, y=imputed_IBU), color="steelblue", size = 1.5) + geom_smooth(aes(x=ABV, y=imputed_IBU),method = "lm")+ labs(x='ABV Value', y="IBU Value", title="Relation between IBU and ABV") + theme_economist() + annotate("text",x=0.12, y=135, label="Correlation: 58%", color="darkred", size=4)
cor(impute_data$ABV, impute_data$imputed_IBU, method = "pearson")
lm1<-lm(ABV~imputed_IBU, data = impute_data)
summary(lm1)
